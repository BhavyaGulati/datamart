{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, random, os\n",
    "sys.path.append(sys.path.append(os.path.join(os.getcwd(), '..')))\n",
    "from datamart.augment import Augment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_index = \"datamart\"\n",
    "\n",
    "augment = Augment(es_index=es_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city country\n0  los angeles      US\n1     New york      US\n2     Shanghai   China\n3        SAFDA    fwfb\n4   manchester      UK\n"
     ]
    }
   ],
   "source": [
    "old_df = pd.DataFrame(data={\n",
    "    'city': [\"los angeles\", \"New york\", \"Shanghai\", \"SAFDA\", \"manchester\"],\n",
    "    'country': [\"US\", \"US\", \"China\", \"fwfb\", \"UK\"],\n",
    "})\n",
    "\n",
    "print(old_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Search metadata\n",
    "Query by a column, which is query on variable.named_entities, by default, if a metadata matches more than half of cells in original dataframe, it is a hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "hitted_metadatas = augment.query_by_column(col=old_df.loc[:, \"city\"])\n",
    "\n",
    "print(len(hitted_metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Can also query by other api\n",
    "hitted_metadatas = augment.query_by_key_value_pairs(key_value_pairs=[\n",
    "    (\"description\", \"average\")\n",
    "])\n",
    "\n",
    "print(len(hitted_metadatas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some ranking methods, say we want to augment with a specific metadata, datamart id 1230000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = augment.query_by_datamart_id(datamart_id=1230000)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = augment.get_dataset(metadata=metadata, variables=None, constrains={\n",
    "            \"locations\": old_df.loc[:, 'city'].unique().tolist(),\n",
    "            \"date_range\": {\n",
    "                \"start\": \"2018-09-23T00:00:00\",\n",
    "                \"end\": \"2018-09-30T00:00:00\"\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    date          stationid         city  TAVG\n63   2018-09-27T00:00:00  GHCND:USW00023129  los angeles   213\n138  2018-09-28T00:00:00  GHCND:CHM00058367     Shanghai   239\n135  2018-09-27T00:00:00  GHCND:CHM00058362     Shanghai   234\n9    2018-09-23T00:00:00  GHCND:USR0000CSFD  los angeles   222\n96   2018-09-30T00:00:00  GHCND:USR0000CCP9  los angeles   188\n80   2018-09-29T00:00:00  GHCND:USR0000CCHB  los angeles   191\n119  2018-09-28T00:00:00  GHCND:USW00014732     New york   174\n77   2018-09-28T00:00:00  GHCND:USW00023174  los angeles   195\n150  2018-09-30T00:00:00  GHCND:USW00014745   manchester   107\n91   2018-09-30T00:00:00  GHCND:USR0000CACT  los angeles   201\n"
     ]
    }
   ],
   "source": [
    "print(new_df.iloc[random.sample(range(1, new_df.shape[0]), 10), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "There are many ways of join between original dataframe and new dataframe.\n",
    "Simplest solution if right join which will produce lots of rows for same city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city country                 date          stationid  TAVG\n0    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CACT   233\n1    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CBEV   206\n2    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CCHB   228\n3    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CCHI   218\n4    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CCLE   237\n5    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CCP9   224\n6    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CLTU   215\n7    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CMAL   197\n8    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CMIL   212\n9    los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CSFD   222\n10   los angeles      US  2018-09-23T00:00:00  GHCND:USR0000CWHH   206\n11   los angeles      US  2018-09-23T00:00:00  GHCND:USW00023129   214\n12   los angeles      US  2018-09-23T00:00:00  GHCND:USW00023174   201\n13   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CACT   206\n14   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CBEV   186\n15   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CCHB   185\n16   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CCHI   208\n17   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CCLE   217\n18   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CCP9   207\n19   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CLTU   181\n20   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CMAL   163\n21   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CMIL   204\n22   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CSFD   204\n23   los angeles      US  2018-09-24T00:00:00  GHCND:USR0000CWHH   187\n24   los angeles      US  2018-09-24T00:00:00  GHCND:USW00023129   203\n25   los angeles      US  2018-09-24T00:00:00  GHCND:USW00023174   196\n26   los angeles      US  2018-09-25T00:00:00  GHCND:USR0000CACT   224\n27   los angeles      US  2018-09-25T00:00:00  GHCND:USR0000CBEV   176\n28   los angeles      US  2018-09-25T00:00:00  GHCND:USR0000CCHB   182\n29   los angeles      US  2018-09-25T00:00:00  GHCND:USR0000CCHI   229\n..           ...     ...                  ...                ...   ...\n121     New york      US  2018-09-28T00:00:00  GHCND:USW00094789   169\n122     New york      US  2018-09-29T00:00:00  GHCND:USW00014732   189\n123     New york      US  2018-09-29T00:00:00  GHCND:USW00014734   176\n124     New york      US  2018-09-29T00:00:00  GHCND:USW00094789   181\n125     New york      US  2018-09-30T00:00:00  GHCND:USW00014732   184\n126     New york      US  2018-09-30T00:00:00  GHCND:USW00014734   167\n127     New york      US  2018-09-30T00:00:00  GHCND:USW00094789   172\n128     Shanghai   China  2018-09-23T00:00:00  GHCND:CHM00058362   253\n129     Shanghai   China  2018-09-23T00:00:00  GHCND:CHM00058367   256\n130     Shanghai   China  2018-09-24T00:00:00  GHCND:CHM00058367   210\n131     Shanghai   China  2018-09-25T00:00:00  GHCND:CHM00058362   232\n132     Shanghai   China  2018-09-25T00:00:00  GHCND:CHM00058367   234\n133     Shanghai   China  2018-09-26T00:00:00  GHCND:CHM00058362   234\n134     Shanghai   China  2018-09-26T00:00:00  GHCND:CHM00058367   235\n135     Shanghai   China  2018-09-27T00:00:00  GHCND:CHM00058362   234\n136     Shanghai   China  2018-09-27T00:00:00  GHCND:CHM00058367   238\n137     Shanghai   China  2018-09-28T00:00:00  GHCND:CHM00058362   239\n138     Shanghai   China  2018-09-28T00:00:00  GHCND:CHM00058367   239\n139     Shanghai   China  2018-09-29T00:00:00  GHCND:CHM00058362   234\n140     Shanghai   China  2018-09-29T00:00:00  GHCND:CHM00058367   231\n141     Shanghai   China  2018-09-30T00:00:00  GHCND:CHM00058362   228\n142     Shanghai   China  2018-09-30T00:00:00  GHCND:CHM00058367   236\n143   manchester      UK  2018-09-23T00:00:00  GHCND:USW00014745   113\n144   manchester      UK  2018-09-24T00:00:00  GHCND:USW00014745   103\n145   manchester      UK  2018-09-25T00:00:00  GHCND:USW00014745    92\n146   manchester      UK  2018-09-26T00:00:00  GHCND:USW00014745   198\n147   manchester      UK  2018-09-27T00:00:00  GHCND:USW00014745   187\n148   manchester      UK  2018-09-28T00:00:00  GHCND:USW00014745   144\n149   manchester      UK  2018-09-29T00:00:00  GHCND:USW00014745   128\n150   manchester      UK  2018-09-30T00:00:00  GHCND:USW00014745   107\n\n[151 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(left=old_df, right=new_df, left_on='city', right_on='city', how='right')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation\n",
    "Join also can be performed based on aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city                 date        TAVG\n0      New york  2018-09-23T00:00:00  174.000000\n1      New york  2018-09-24T00:00:00  176.333333\n2      New york  2018-09-25T00:00:00  184.666667\n3      New york  2018-09-26T00:00:00  239.333333\n4      New york  2018-09-27T00:00:00  206.666667\n5      New york  2018-09-28T00:00:00  170.000000\n6      New york  2018-09-29T00:00:00  182.000000\n7      New york  2018-09-30T00:00:00  174.333333\n8      Shanghai  2018-09-23T00:00:00  254.500000\n9      Shanghai  2018-09-24T00:00:00  210.000000\n10     Shanghai  2018-09-25T00:00:00  233.000000\n11     Shanghai  2018-09-26T00:00:00  234.500000\n12     Shanghai  2018-09-27T00:00:00  236.000000\n13     Shanghai  2018-09-28T00:00:00  239.000000\n14     Shanghai  2018-09-29T00:00:00  232.500000\n15     Shanghai  2018-09-30T00:00:00  232.000000\n16  los angeles  2018-09-23T00:00:00  216.384615\n17  los angeles  2018-09-24T00:00:00  195.923077\n18  los angeles  2018-09-25T00:00:00  202.923077\n19  los angeles  2018-09-26T00:00:00  227.538462\n20  los angeles  2018-09-27T00:00:00  238.692308\n21  los angeles  2018-09-28T00:00:00  212.615385\n22  los angeles  2018-09-29T00:00:00  192.692308\n23  los angeles  2018-09-30T00:00:00  209.692308\n24   manchester  2018-09-23T00:00:00  113.000000\n25   manchester  2018-09-24T00:00:00  103.000000\n26   manchester  2018-09-25T00:00:00   92.000000\n27   manchester  2018-09-26T00:00:00  198.000000\n28   manchester  2018-09-27T00:00:00  187.000000\n29   manchester  2018-09-28T00:00:00  144.000000\n30   manchester  2018-09-29T00:00:00  128.000000\n31   manchester  2018-09-30T00:00:00  107.000000\n"
     ]
    }
   ],
   "source": [
    "new_df_aggregated = new_df.groupby([\"city\", \"date\"], as_index=False)[\"TAVG\"].mean()\n",
    "print(new_df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city country                 date        TAVG\n0   los angeles      US  2018-09-23T00:00:00  216.384615\n1   los angeles      US  2018-09-24T00:00:00  195.923077\n2   los angeles      US  2018-09-25T00:00:00  202.923077\n3   los angeles      US  2018-09-26T00:00:00  227.538462\n4   los angeles      US  2018-09-27T00:00:00  238.692308\n5   los angeles      US  2018-09-28T00:00:00  212.615385\n6   los angeles      US  2018-09-29T00:00:00  192.692308\n7   los angeles      US  2018-09-30T00:00:00  209.692308\n8      New york      US  2018-09-23T00:00:00  174.000000\n9      New york      US  2018-09-24T00:00:00  176.333333\n10     New york      US  2018-09-25T00:00:00  184.666667\n11     New york      US  2018-09-26T00:00:00  239.333333\n12     New york      US  2018-09-27T00:00:00  206.666667\n13     New york      US  2018-09-28T00:00:00  170.000000\n14     New york      US  2018-09-29T00:00:00  182.000000\n15     New york      US  2018-09-30T00:00:00  174.333333\n16     Shanghai   China  2018-09-23T00:00:00  254.500000\n17     Shanghai   China  2018-09-24T00:00:00  210.000000\n18     Shanghai   China  2018-09-25T00:00:00  233.000000\n19     Shanghai   China  2018-09-26T00:00:00  234.500000\n20     Shanghai   China  2018-09-27T00:00:00  236.000000\n21     Shanghai   China  2018-09-28T00:00:00  239.000000\n22     Shanghai   China  2018-09-29T00:00:00  232.500000\n23     Shanghai   China  2018-09-30T00:00:00  232.000000\n24   manchester      UK  2018-09-23T00:00:00  113.000000\n25   manchester      UK  2018-09-24T00:00:00  103.000000\n26   manchester      UK  2018-09-25T00:00:00   92.000000\n27   manchester      UK  2018-09-26T00:00:00  198.000000\n28   manchester      UK  2018-09-27T00:00:00  187.000000\n29   manchester      UK  2018-09-28T00:00:00  144.000000\n30   manchester      UK  2018-09-29T00:00:00  128.000000\n31   manchester      UK  2018-09-30T00:00:00  107.000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(left=old_df, right=new_df_aggregated, left_on='city', right_on='city', how='right')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also unstack new datagrame to form more columns and so that we will not produce extra rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date         city  2018-09-23T00:00:00  2018-09-24T00:00:00  \\\n0        New york           174.000000           176.333333   \n1        Shanghai           254.500000           210.000000   \n2     los angeles           216.384615           195.923077   \n3      manchester           113.000000           103.000000   \n\ndate  2018-09-25T00:00:00  2018-09-26T00:00:00  2018-09-27T00:00:00  \\\n0              184.666667           239.333333           206.666667   \n1              233.000000           234.500000           236.000000   \n2              202.923077           227.538462           238.692308   \n3               92.000000           198.000000           187.000000   \n\ndate  2018-09-28T00:00:00  2018-09-29T00:00:00  2018-09-30T00:00:00  \n0              170.000000           182.000000           174.333333  \n1              239.000000           232.500000           232.000000  \n2              212.615385           192.692308           209.692308  \n3              144.000000           128.000000           107.000000  \n"
     ]
    }
   ],
   "source": [
    "new_df_unstacked = new_df.groupby([\"city\", \"date\"])[\"TAVG\"].mean().unstack().reset_index(level=['city'])\n",
    "print(new_df_unstacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city country  2018-09-23T00:00:00  2018-09-24T00:00:00  \\\n0  los angeles      US           216.384615           195.923077   \n1     New york      US           174.000000           176.333333   \n2     Shanghai   China           254.500000           210.000000   \n3   manchester      UK           113.000000           103.000000   \n\n   2018-09-25T00:00:00  2018-09-26T00:00:00  2018-09-27T00:00:00  \\\n0           202.923077           227.538462           238.692308   \n1           184.666667           239.333333           206.666667   \n2           233.000000           234.500000           236.000000   \n3            92.000000           198.000000           187.000000   \n\n   2018-09-28T00:00:00  2018-09-29T00:00:00  2018-09-30T00:00:00  \n0           212.615385           192.692308           209.692308  \n1           170.000000           182.000000           174.333333  \n2           239.000000           232.500000           232.000000  \n3           144.000000           128.000000           107.000000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(left=old_df, right=new_df_unstacked, left_on='city', right_on='city')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
